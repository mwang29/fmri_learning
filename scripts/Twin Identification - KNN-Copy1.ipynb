{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utri2mat(utri):\n",
    "    n = int(-1 + np.sqrt(1 + 8 * len(utri))) // 2\n",
    "    iu1 = np.triu_indices(n+1,1)\n",
    "    ret = np.empty((n+1, n+1))\n",
    "    ret[iu1] = utri\n",
    "    ret.T[iu1] = utri\n",
    "    np.fill_diagonal(ret, 1)\n",
    "    return ret\n",
    "\n",
    "def get_data(test_idx, retest_idx, parc, twin='DZ'):\n",
    "    '''\n",
    "    Navigates through file tree and extracts FCs with optional reconstruction\n",
    "    '''\n",
    "    # Yeo ordering\n",
    "    master_dir = '../data/twins'\n",
    "    tasks = ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']\n",
    "    FC, test, retest = {}, {}, {}\n",
    "    for task in tasks:\n",
    "        temp_parc = {}\n",
    "        task_dir = master_dir + f'/{task.upper()}/origmat_{twin}_schaefer{parc}_tests.mat'\n",
    "        f = h5py.File(task_dir, 'r')\n",
    "        for k, v in f.items():\n",
    "            temp_parc[k] = np.array(v)\n",
    "        test[task] = temp_parc['orig_mat'][test_idx[task]]\n",
    "        temp_parc = {}\n",
    "        task_dir = master_dir + f'/{task.upper()}/origmat_{twin}_schaefer{parc}_retests.mat'\n",
    "        f = h5py.File(task_dir, 'r')\n",
    "        for k, v in f.items():\n",
    "            temp_parc[k] = np.array(v)\n",
    "        retest[task] = temp_parc['orig_mat'][retest_idx[task]]\n",
    "        FC[task] = np.concatenate((test[task], retest[task])) \n",
    "        FC[task] = test[task]\n",
    "    return FC\n",
    "\n",
    "\n",
    "def q1invm(q1, eig_thresh=0):\n",
    "    U, S, V = scipy.linalg.svd(q1)\n",
    "    s = np.diag(S)\n",
    "    s[s < eig_thresh] = eig_thresh\n",
    "    S = np.diag(s ** (-1 / 2))\n",
    "    Q1_inv_sqrt = U * S * np.transpose(V)\n",
    "    Q1_inv_sqrt = (Q1_inv_sqrt + np.transpose(Q1_inv_sqrt)) / 2\n",
    "    return Q1_inv_sqrt\n",
    "\n",
    "\n",
    "def qlog(q):\n",
    "    U, S, V = scipy.linalg.svd(q)\n",
    "    s = np.diag(S)\n",
    "    S = np.diag(np.log(s))\n",
    "    Q = U * S * np.transpose(V)\n",
    "    return Q\n",
    "\n",
    "\n",
    "def tangential(all_FC, ref):\n",
    "    # Regularization for riemann\n",
    "    if ref in ['riemann', 'kullback_sym', 'logeuclid']: \n",
    "        print(\"Adding regularization!\")\n",
    "        eye_mat = np.eye(all_FC.shape[1])\n",
    "        scaling_mat = np.repeat(eye_mat[None, ...], all_FC.shape[0], axis=0)\n",
    "        all_FC += scaling_mat\n",
    "    u, s, vh = np.linalg.svd(all_FC[0], full_matrices=True)\n",
    "    Cg = mean_covariance(all_FC, metric=ref)\n",
    "    Q1_inv_sqrt = q1invm(Cg)\n",
    "    Q = Q1_inv_sqrt @ all_FC @ Q1_inv_sqrt\n",
    "    tangent_FC = np.array([qlog(a) for a in Q])\n",
    "    return tangent_FC\n",
    "\n",
    "\n",
    "def pca_recon(FC, pctComp=None):\n",
    "    '''\n",
    "    Reconstructs FC based on number of principle components\n",
    "    '''\n",
    "    if pctComp is None:\n",
    "        return FC\n",
    "    nRegions = FC.shape[1]\n",
    "    FC = np.reshape(FC, (FC.shape[0], -1))\n",
    "    nComp = int(FC.shape[0] * pctComp)\n",
    "    mu = np.mean(FC, axis=0)\n",
    "    pca_rest = sklearn.decomposition.PCA()\n",
    "    pca_rest.fit(FC)\n",
    "    SCORES = pca_rest.transform(FC)[:, :nComp]\n",
    "    COEFFS = pca_rest.components_[:nComp, :]\n",
    "    FC_recon = np.dot(SCORES, COEFFS)\n",
    "    del SCORES, COEFFS\n",
    "    FC_recon += mu\n",
    "    FC_recon = np.reshape(FC_recon, (FC.shape[0], nRegions, nRegions))\n",
    "    return FC_recon\n",
    "\n",
    "def utri2mat(utri):\n",
    "    n = int(-1 + np.sqrt(1 + 8 * len(utri))) // 2\n",
    "    iu1 = np.tril_indices(n+1,-1)\n",
    "    ret = np.empty((n+1, n+1))\n",
    "    ret[iu1] = utri\n",
    "    ret.T[iu1] = utri\n",
    "    np.fill_diagonal(ret, 1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twin Subject ID Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twin = \"MZ\"\n",
    "tasks = ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']\n",
    "test_subj_ids, retest_subj_ids = {}, {}\n",
    "for task in tasks:\n",
    "    test_subj_vec, retest_subj_vec = {}, {}\n",
    "    master_dir = '../data/twins'\n",
    "    test_subj_dir = master_dir + f'/{task.upper()}/subjvec_test_{twin}_schaefer300_retests.mat'\n",
    "    retest_subj_dir = master_dir + f'/{task.upper()}/subjvec_retest_{twin}_schaefer300_retests.mat'\n",
    "    f = h5py.File(test_subj_dir, 'r')\n",
    "    for k, v in f.items():\n",
    "        test_subj_vec[k] = np.array(v)\n",
    "    f = h5py.File(retest_subj_dir, 'r')\n",
    "    for k, v in f.items():\n",
    "        retest_subj_vec[k] = np.array(v)\n",
    "    test_subj_ids[task] = test_subj_vec['subj_vec'].astype(int)\n",
    "    retest_subj_ids[task] = retest_subj_vec['subj_vec'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_twin1, retest_twin1 = {}, {}\n",
    "for task in tasks:\n",
    "    test_twin1[task]= set(test_subj_ids[task][0])\n",
    "    retest_twin1[task] = set(retest_subj_ids[task][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common twins over all tasks, test/retest: 106\n"
     ]
    }
   ],
   "source": [
    "# How many twin pairs are common between tasks?\n",
    "common_twins = set.intersection(test_twin1['rest'], test_twin1['emotion'], test_twin1['gambling'],test_twin1['language'], test_twin1['motor'],test_twin1['relational'], test_twin1['social'],test_twin1['wm'],\n",
    "                                retest_twin1['rest'], retest_twin1['emotion'], retest_twin1['gambling'],retest_twin1['language'], retest_twin1['motor'],retest_twin1['relational'], retest_twin1['social'],retest_twin1['wm'])\n",
    "num_common_twins = len(common_twins)\n",
    "print(f'Number of common twins over all tasks, test/retest: {num_common_twins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of each task only for the common twins\n",
    "test_twin_ind, retest_twin_ind = {}, {}\n",
    "for task in tasks:\n",
    "    test_twin_ind[task]= [2*i for i, val in enumerate(test_twin1[task]) if val in common_twins]\n",
    "    test_twin_ind[task] = test_twin_ind[task] + [x+1 for x in test_twin_ind[task]]\n",
    "    test_twin_ind[task].sort()\n",
    "    retest_twin_ind[task]= [2*i for i, val in enumerate(retest_twin1[task]) if val in common_twins] \n",
    "    retest_twin_ind[task] = retest_twin_ind[task] + [x+1 for x in retest_twin_ind[task]]\n",
    "    retest_twin_ind[task].sort()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_FCs = get_data(test_twin_ind, retest_twin_ind, 100, twin=twin)\n",
    "labels = np.repeat(np.arange(0,common_FCs['rest'].shape[0]/2),2)\n",
    "labels = labels.astype(int)\n",
    "train_idx = np.arange(0,common_FCs['rest'].shape[0],2)\n",
    "train_idx = train_idx.astype(int)\n",
    "test_idx = np.arange(1, int(common_FCs['rest'].shape[0]), 2)\n",
    "test_idx = test_idx.astype(int)\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFCs = common_FCs['rest'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing rest...\n",
      "0.32075 accuracy\n",
      "Analyzing emotion...\n",
      "0.09434 accuracy\n",
      "Analyzing gambling...\n",
      "0.15094 accuracy\n",
      "Analyzing language...\n",
      "0.29245 accuracy\n",
      "Analyzing motor...\n",
      "0.07547 accuracy\n",
      "Analyzing relational...\n",
      "0.08491 accuracy\n",
      "Analyzing social...\n",
      "0.20755 accuracy\n",
      "Analyzing wm...\n",
      "0.25472 accuracy\n",
      "Analyzing rest...\n",
      "0.40566 accuracy\n",
      "Analyzing emotion...\n",
      "0.10377 accuracy\n",
      "Analyzing gambling...\n",
      "0.17925 accuracy\n",
      "Analyzing language...\n",
      "0.39623 accuracy\n",
      "Analyzing motor...\n",
      "0.10377 accuracy\n",
      "Analyzing relational...\n",
      "0.15094 accuracy\n",
      "Analyzing social...\n",
      "0.31132 accuracy\n",
      "Analyzing wm...\n",
      "0.36792 accuracy\n",
      "Analyzing rest...\n",
      "0.43396 accuracy\n",
      "Analyzing emotion...\n",
      "0.09434 accuracy\n",
      "Analyzing gambling...\n",
      "0.23585 accuracy\n",
      "Analyzing language...\n",
      "0.40566 accuracy\n",
      "Analyzing motor...\n",
      "0.08491 accuracy\n",
      "Analyzing relational...\n",
      "0.18868 accuracy\n",
      "Analyzing social...\n",
      "0.33962 accuracy\n",
      "Analyzing wm...\n",
      "0.41509 accuracy\n",
      "Analyzing rest...\n",
      "0.45283 accuracy\n",
      "Analyzing emotion...\n",
      "0.12264 accuracy\n",
      "Analyzing gambling...\n",
      "0.22642 accuracy\n",
      "Analyzing language...\n",
      "0.46226 accuracy\n",
      "Analyzing motor...\n",
      "0.10377 accuracy\n",
      "Analyzing relational...\n",
      "0.17925 accuracy\n",
      "Analyzing social...\n",
      "0.33962 accuracy\n",
      "Analyzing wm...\n",
      "0.44340 accuracy\n",
      "Analyzing rest...\n",
      "0.46226 accuracy\n",
      "Analyzing emotion...\n",
      "0.12264 accuracy\n",
      "Analyzing gambling...\n",
      "0.24528 accuracy\n",
      "Analyzing language...\n",
      "0.49057 accuracy\n",
      "Analyzing motor...\n",
      "0.09434 accuracy\n",
      "Analyzing relational...\n",
      "0.19811 accuracy\n",
      "Analyzing social...\n",
      "0.34906 accuracy\n",
      "Analyzing wm...\n",
      "0.47170 accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for parc in np.arange(100, 600, 100):\n",
    "    common_FCs = get_data(test_twin_ind, retest_twin_ind, parc, twin=twin)\n",
    "    for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "        print(f'Analyzing {task}...')\n",
    "        task_FCs = common_FCs[task]\n",
    "        # Do optional transformations\n",
    "        for ref in ['Raw FC']: #, 'pca', 'euclid', 'harmonic']:\n",
    "            # Start with a fresh batch of FCs\n",
    "            FC = np.zeros((task_FCs.shape[0], parc+14, parc+14))\n",
    "            for idx, utri in enumerate(task_FCs):\n",
    "                FC[idx] = utri2mat(utri)\n",
    "            # Do optional transformations\n",
    "            if ref != 'Raw FC' and ref != 'pca':\n",
    "                FC = tangential(FC, ref)\n",
    "            elif ref == 'pca':\n",
    "                print('Reconstructing with PCA')\n",
    "                FC = pca_recon(FC, 0.3)\n",
    "            else:\n",
    "                pass\n",
    "            # Convert back into flattened utriu vectors\n",
    "            vec_FCs = np.zeros(\n",
    "                (nFCs, lengths[parc]), dtype=np.float32)\n",
    "            for idx, mat in enumerate(FC):\n",
    "                vec_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "            # Split into train and test sets\n",
    "            train_FCs = vec_FCs[train_idx]\n",
    "            test_FCs = vec_FCs[test_idx]\n",
    "            # KNN Classifier\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, metric='correlation')\n",
    "            neigh.fit(train_FCs, train_labels)\n",
    "            predicted = neigh.predict(test_FCs)\n",
    "            acc = accuracy_score(test_labels, predicted)\n",
    "            print(f'{acc:.5f} accuracy')\n",
    "            accuracies[f\"{parc}:{task}\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/twins/{twin}_twin_parcellations_single.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent Space FCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 region parcellation...\n",
      "Analyzing rest...\n",
      "0.65094 accuracy\n",
      "Analyzing emotion...\n",
      "0.39623 accuracy\n",
      "Analyzing gambling...\n",
      "0.46226 accuracy\n",
      "Analyzing language...\n",
      "0.67925 accuracy\n",
      "Analyzing motor...\n",
      "0.41509 accuracy\n",
      "Analyzing relational...\n",
      "0.48113 accuracy\n",
      "Analyzing social...\n",
      "0.59434 accuracy\n",
      "Analyzing wm...\n",
      "0.66038 accuracy\n",
      "Using 200 region parcellation...\n",
      "Analyzing rest...\n",
      "0.82075 accuracy\n",
      "Analyzing emotion...\n",
      "0.57547 accuracy\n",
      "Analyzing gambling...\n",
      "0.73585 accuracy\n",
      "Analyzing language...\n",
      "0.86792 accuracy\n",
      "Analyzing motor...\n",
      "0.71698 accuracy\n",
      "Analyzing relational...\n",
      "0.74528 accuracy\n",
      "Analyzing social...\n",
      "0.80189 accuracy\n",
      "Analyzing wm...\n",
      "0.83962 accuracy\n",
      "Using 300 region parcellation...\n",
      "Analyzing rest...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-fe1e8a2423d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Start with a fresh batch of FCs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../data/tangent_fcs/twins/{task}/{twin}_{parc}_{ref}.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mFC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mFC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Convert back into flattened utriu vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "twin = 'MZ'\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for parc in np.arange(100,500,100):\n",
    "    print(f'Using {parc} region parcellation...')\n",
    "    for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "        print(f'Analyzing {task}...')\n",
    "        for ref in ['logeuclid']:\n",
    "            # Start with a fresh batch of FCs\n",
    "            with open(f'../data/tangent_fcs/twins/{task}/{twin}_{parc}_{ref}.pickle', 'rb') as f:\n",
    "                FC = pickle.load(f)\n",
    "                FC = FC[:211]\n",
    "            # Convert back into flattened utriu vectors\n",
    "            vec_FCs = np.zeros((nFCs, lengths[parc]), dtype=np.float32)\n",
    "            for idx, mat in enumerate(FC):\n",
    "                vec_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "            # Split into train and test sets\n",
    "            train_FCs = vec_FCs[train_idx]\n",
    "            test_FCs = vec_FCs[test_idx]\n",
    "            # KNN Classifier\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, metric='correlation')\n",
    "            neigh.fit(train_FCs, train_labels)\n",
    "            predicted = neigh.predict(test_FCs)\n",
    "            acc = accuracy_score(test_labels, predicted)\n",
    "            print(f'{acc:.5f} accuracy')\n",
    "            accuracies[f\"{parc}:{task}\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/twins/{twin}_twin_logeuclid.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
