{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data():\n",
    "    '''\n",
    "    Navigates through file tree and extracts FCs with optional reconstruction\n",
    "    '''\n",
    "    # Yeo ordering\n",
    "    fname = '../data/100_unrelated.csv'\n",
    "    yeo = True\n",
    "    if yeo:\n",
    "        yeo_order = list(sio.loadmat(\"../data/yeo_RS7_N374.mat\",\n",
    "                                     squeeze_me=True,\n",
    "                                     struct_as_record=False)['yeoOrder'] - 1)\n",
    "    # Load subject ID and task names\n",
    "    subjectids = np.loadtxt(fname, dtype=np.int)\n",
    "    nSubj = len(subjectids)\n",
    "    tasks = ['rfMRI_REST1_LR', 'rfMRI_REST1_RL', 'rfMRI_REST2_LR',\n",
    "             'rfMRI_REST2_RL', 'tfMRI_EMOTION_LR', 'tfMRI_EMOTION_RL',\n",
    "             'tfMRI_GAMBLING_LR', 'tfMRI_GAMBLING_RL', 'tfMRI_LANGUAGE_LR',\n",
    "             'tfMRI_LANGUAGE_RL', 'tfMRI_MOTOR_LR', 'tfMRI_MOTOR_RL',\n",
    "             'tfMRI_RELATIONAL_LR', 'tfMRI_RELATIONAL_RL', 'tfMRI_SOCIAL_LR',\n",
    "             'tfMRI_SOCIAL_RL', 'tfMRI_WM_LR', 'tfMRI_WM_RL']\n",
    "    M = {}\n",
    "    # Walk through file tree and extract FCs\n",
    "    for task in tasks:\n",
    "        masterFC_dir = '../data/results_SIFT2'\n",
    "        restingstatename = 'fMRI/' + task + '/FC/FC_glasser_subc_GS_bp_z.mat'\n",
    "        task_matrices = []\n",
    "        for subject in subjectids:\n",
    "            filename = masterFC_dir + '/' + \\\n",
    "                str(subject) + '/' + restingstatename\n",
    "            mat = sio.loadmat(filename, squeeze_me=True,\n",
    "                              struct_as_record=False)\n",
    "            A_orig = mat['FC']\n",
    "            if yeo:\n",
    "                A_orig = A_orig[np.ix_(yeo_order, yeo_order)]\n",
    "            np.fill_diagonal(A_orig, 1)\n",
    "            task_matrices.append(A_orig)\n",
    "        M[task] = np.array(task_matrices)\n",
    "    test = np.concatenate((M['rfMRI_REST1_LR'], M['tfMRI_EMOTION_LR'],\n",
    "                           M['tfMRI_GAMBLING_LR'], M['tfMRI_LANGUAGE_LR'],\n",
    "                           M['tfMRI_MOTOR_LR'], M['tfMRI_RELATIONAL_LR'],\n",
    "                           M['tfMRI_SOCIAL_LR'], M['tfMRI_WM_LR']))\n",
    "    retest = np.concatenate((M['rfMRI_REST1_RL'], M['tfMRI_EMOTION_RL'],\n",
    "                             M['tfMRI_GAMBLING_RL'], M['tfMRI_LANGUAGE_RL'],\n",
    "                             M['tfMRI_MOTOR_RL'], M['tfMRI_RELATIONAL_RL'],\n",
    "                             M['tfMRI_SOCIAL_RL'], M['tfMRI_WM_RL']))\n",
    "    del M\n",
    "    all_FC = np.concatenate((test, retest))\n",
    "    del test, retest\n",
    "    return all_FC, nSubj\n",
    "\n",
    "\n",
    "def q1invm(q1, eig_thresh=0):\n",
    "    U, S, V = scipy.linalg.svd(q1)\n",
    "    s = np.diag(S)\n",
    "    s[s < eig_thresh] = eig_thresh\n",
    "    S = np.diag(s ** (-1 / 2))\n",
    "    Q1_inv_sqrt = U * S * np.transpose(V)\n",
    "    Q1_inv_sqrt = (Q1_inv_sqrt + np.transpose(Q1_inv_sqrt)) / 2\n",
    "    return Q1_inv_sqrt\n",
    "\n",
    "\n",
    "def qlog(q):\n",
    "    U, S, V = scipy.linalg.svd(q)\n",
    "    s = np.diag(S)\n",
    "    S = np.diag(np.log(s))\n",
    "    Q = U * S * np.transpose(V)\n",
    "    return Q\n",
    "\n",
    "\n",
    "def tangential(all_FC, ref):\n",
    "    # Regularization for riemann\n",
    "    if ref in ['riemann', 'kullback_sym', 'logeuclid']:\n",
    "        print(\"Adding regularization!\")\n",
    "        eye_mat = np.eye(all_FC.shape[1])\n",
    "        scaling_mat = np.repeat(eye_mat[None, ...], all_FC.shape[0], axis=0)\n",
    "        all_FC += scaling_mat\n",
    "    Cg = mean_covariance(all_FC, metric=ref)\n",
    "    Q1_inv_sqrt = q1invm(Cg)\n",
    "    Q = Q1_inv_sqrt @ all_FC @ Q1_inv_sqrt\n",
    "    tangent_FC = np.array([qlog(a) for a in Q])\n",
    "    return tangent_FC\n",
    "\n",
    "\n",
    "def pca_recon(FC, pctComp=None):\n",
    "    '''\n",
    "    Reconstructs FC based on number of principle components\n",
    "    '''\n",
    "    if pctComp is None:\n",
    "        return FC\n",
    "    FC = np.reshape(FC, (FC.shape[0], -1))\n",
    "    nComp = int(FC.shape[0] * pctComp)\n",
    "    mu = np.mean(FC, axis=0)\n",
    "    pca_rest = sklearn.decomposition.PCA()\n",
    "    pca_rest.fit(FC)\n",
    "    SCORES = pca_rest.transform(FC)[:, :nComp]\n",
    "    COEFFS = pca_rest.components_[:nComp, :]\n",
    "    FC_recon = np.dot(SCORES, COEFFS)\n",
    "    del SCORES, COEFFS\n",
    "    FC_recon += mu\n",
    "    FC_recon = np.reshape(FC_recon, (FC.shape[0], 374, 374))\n",
    "    return FC_recon\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing all correlation matrices... All FCs successfully loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Navigate tree and get raw correlation FC matrices\n",
    "print(\"Importing all correlation matrices...\", end=\" \")\n",
    "all_FC, nSubj = get_data()\n",
    "print(\"All FCs successfully loaded!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = 'subject'\n",
    "if classifier == 'task':\n",
    "    labels = np.tile(np.repeat(np.arange(0, 8), nSubj), 2)\n",
    "    indices = np.random.permutation(nSubj)\n",
    "    train_idx = indices[:int(0.80 * nSubj)]\n",
    "    test_idx = indices[int(0.8 * nSubj):]\n",
    "    train_idx_all, test_idx_all = np.empty(0, dtype=int), np.empty(0, dtype=int)\n",
    "    for fc in np.arange(0, 16):\n",
    "        train_idx_all = np.concatenate((train_idx_all, (fc * 95) + train_idx)).astype(int)\n",
    "        test_idx_all = np.concatenate((test_idx_all, (fc * 95) + test_idx)).astype(int)\n",
    "    train_idx = train_idx_all\n",
    "    test_idx = test_idx_all\n",
    "elif classifier == 'subject':\n",
    "    labels = np.tile(np.tile(np.arange(0,nSubj),8),2)\n",
    "    indices = np.random.permutation(all_FC.shape[0])\n",
    "    train_idx = indices[:int(0.80 * all_FC.shape[0])]\n",
    "    test_idx = indices[int(0.80 * all_FC.shape[0]):]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing euclid and corr...\n",
      "0.019736842105263157\n",
      "Testing euclid and cosine...\n",
      "0.019736842105263157\n",
      "Testing euclid and euclidean...\n",
      "0.019736842105263157\n",
      "Testing harmonic and corr...\n",
      "0.003289473684210526\n",
      "Testing harmonic and cosine...\n",
      "0.003289473684210526\n",
      "Testing harmonic and euclidean...\n",
      "0.006578947368421052\n",
      "Adding regularization!\n",
      "Testing logeuclid and corr...\n",
      "0.039473684210526314\n",
      "Testing logeuclid and cosine...\n",
      "0.039473684210526314\n",
      "Testing logeuclid and euclidean...\n",
      "0.03289473684210526\n",
      "Adding regularization!\n",
      "Testing kullback_sym and corr...\n",
      "0.046052631578947366\n",
      "Testing kullback_sym and cosine...\n",
      "0.049342105263157895\n",
      "Testing kullback_sym and euclidean...\n",
      "0.05592105263157895\n",
      "Adding regularization!\n",
      "Testing riemann and corr...\n",
      "0.05263157894736842\n",
      "Testing riemann and cosine...\n",
      "0.05263157894736842\n",
      "Testing riemann and euclidean...\n",
      "0.05592105263157895\n",
      "Testing none and corr...\n",
      "0.7335526315789473\n",
      "Testing none and cosine...\n",
      "0.7335526315789473\n",
      "Testing none and euclidean...\n",
      "0.6085526315789473\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "for ref in ['euclid', 'harmonic', 'logeuclid', 'kullback_sym', 'riemann', 'none']:\n",
    "    all_FC, nSubj = get_data()\n",
    "    if ref != 'none':\n",
    "        all_FC = tangential(all_FC, ref)\n",
    "    train_FCs = np.zeros((len(train_idx),70125), dtype=np.float32)\n",
    "    for idx, mat in enumerate(all_FC[train_idx]):\n",
    "        train_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=0)]\n",
    "    test_FCs = np.zeros((len(test_idx),70125), dtype=np.float32)\n",
    "    for idx, mat in enumerate(all_FC[test_idx]):\n",
    "        test_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=0)]\n",
    "        \n",
    "    for distance_method in ['corr', 'cosine', 'euclidean']:\n",
    "        print(f'Testing {ref} and {distance_method}...')\n",
    "        num_correct = 0\n",
    "        for idx1, mat1 in enumerate(test_FCs):\n",
    "            min_dist = np.inf\n",
    "            true_label = labels[test_idx[idx1]]\n",
    "            for idx2, mat2 in enumerate(train_FCs):\n",
    "                if distance_method == 'corr':\n",
    "                    temp_dist = distance.correlation(mat1, mat2)\n",
    "                elif distance_method == 'cosine':\n",
    "                    temp_dist = distance.cosine(mat1, mat2)\n",
    "                else:\n",
    "                    temp_dist = distance.euclidean(mat1, mat2)\n",
    "                if temp_dist < min_dist:\n",
    "                    min_dist = temp_dist\n",
    "                    best_idx = train_idx[idx2]\n",
    "            pred_label = labels[best_idx]\n",
    "            if pred_label == true_label:\n",
    "                num_correct += 1\n",
    "        accuracy = num_correct / len(test_idx)\n",
    "        print(accuracy)\n",
    "        accuracies[ref+\"_\"+distance_method] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "a_file = open(f\"../results/distances_{classifier}.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing euclid reference with correlation distance...\n",
      "0.0\n",
      "Testing euclid reference with cosine distance...\n",
      "0.0\n",
      "Testing euclid reference with euclidean distance...\n",
      "0.0\n",
      "Testing harmonic reference with correlation distance...\n",
      "0.0\n",
      "Testing harmonic reference with cosine distance...\n",
      "0.0\n",
      "Testing harmonic reference with euclidean distance...\n",
      "0.006578947368421052\n",
      "Adding regularization!\n",
      "Testing logeuclid reference with correlation distance...\n",
      "0.049342105263157895\n",
      "Testing logeuclid reference with cosine distance...\n",
      "0.04276315789473684\n",
      "Testing logeuclid reference with euclidean distance...\n",
      "0.046052631578947366\n",
      "Adding regularization!\n",
      "Testing kullback_sym reference with correlation distance...\n",
      "0.05263157894736842\n",
      "Testing kullback_sym reference with cosine distance...\n",
      "0.05921052631578947\n",
      "Testing kullback_sym reference with euclidean distance...\n",
      "0.05921052631578947\n",
      "Adding regularization!\n",
      "Testing riemann reference with correlation distance...\n",
      "0.03618421052631579\n",
      "Testing riemann reference with cosine distance...\n",
      "0.039473684210526314\n",
      "Testing riemann reference with euclidean distance...\n",
      "0.05592105263157895\n",
      "Testing none reference with correlation distance...\n",
      "0.3881578947368421\n",
      "Testing none reference with cosine distance...\n",
      "0.39144736842105265\n",
      "Testing none reference with euclidean distance...\n",
      "0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "for ref in ['euclid', 'harmonic', 'logeuclid', 'kullback_sym', 'riemann', 'none']:\n",
    "    all_FC, nSubj = get_data()\n",
    "    if ref != 'none':\n",
    "        all_FC = tangential(all_FC, ref)\n",
    "    train_FCs = np.zeros((len(train_idx),70125), dtype=np.float32)\n",
    "    for idx, mat in enumerate(all_FC[train_idx]):\n",
    "        train_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=0)]\n",
    "    test_FCs = np.zeros((len(test_idx),70125), dtype=np.float32)\n",
    "    for idx, mat in enumerate(all_FC[test_idx]):\n",
    "        test_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=0)]\n",
    "        \n",
    "    for distance_method in ['correlation', 'cosine', 'euclidean']:\n",
    "        print(f'Testing {ref} reference with {distance_method} distance...')\n",
    "        neigh = KNeighborsClassifier(n_neighbors=30, metric=distance_method)\n",
    "        neigh.fit(train_FCs, train_labels)\n",
    "        predicted = neigh.predict(test_FCs)\n",
    "        acc = accuracy_score(test_labels, predicted)\n",
    "        print(acc)\n",
    "        accuracies[ref+\"_\"+distance_method] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/knn_distances_{classifier}.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
