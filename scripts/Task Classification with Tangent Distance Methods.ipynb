{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import scipy\n",
    "import pickle\n",
    "from scipy import linalg\n",
    "import scipy.io as sio\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_glasser():\n",
    "    '''\n",
    "    Navigates through file tree and extracts FCs with optional reconstruction\n",
    "    '''\n",
    "    # Yeo ordering\n",
    "    fname = '../data/100_unrelated.csv'\n",
    "    yeo = True\n",
    "    if yeo:\n",
    "        yeo_order = list(sio.loadmat(\"../data/yeo_RS7_N374.mat\",\n",
    "                                     squeeze_me=True,\n",
    "                                     struct_as_record=False)['yeoOrder'] - 1)\n",
    "    # Load subject ID and task names\n",
    "    subjectids = np.loadtxt(fname, dtype=np.int)\n",
    "    nSubj = len(subjectids)\n",
    "    tasks = ['rfMRI_REST1_LR', 'rfMRI_REST1_RL', 'rfMRI_REST2_LR',\n",
    "             'rfMRI_REST2_RL', 'tfMRI_EMOTION_LR', 'tfMRI_EMOTION_RL',\n",
    "             'tfMRI_GAMBLING_LR', 'tfMRI_GAMBLING_RL', 'tfMRI_LANGUAGE_LR',\n",
    "             'tfMRI_LANGUAGE_RL', 'tfMRI_MOTOR_LR', 'tfMRI_MOTOR_RL',\n",
    "             'tfMRI_RELATIONAL_LR', 'tfMRI_RELATIONAL_RL', 'tfMRI_SOCIAL_LR',\n",
    "             'tfMRI_SOCIAL_RL', 'tfMRI_WM_LR', 'tfMRI_WM_RL']\n",
    "    M = {}\n",
    "    # Walk through file tree and extract FCs\n",
    "    for task in tasks:\n",
    "        masterFC_dir = '../data/results_SIFT2'\n",
    "        restingstatename = 'fMRI/' + task + '/FC/FC_glasser_subc_GS_bp_z.mat'\n",
    "        task_matrices = []\n",
    "        for subject in subjectids:\n",
    "            filename = masterFC_dir + '/' + \\\n",
    "                str(subject) + '/' + restingstatename\n",
    "            mat = sio.loadmat(filename, squeeze_me=True,\n",
    "                              struct_as_record=False)\n",
    "            A_orig = mat['FC']\n",
    "            if yeo:\n",
    "                A_orig = A_orig[np.ix_(yeo_order, yeo_order)]\n",
    "            np.fill_diagonal(A_orig, 1)\n",
    "            task_matrices.append(A_orig)\n",
    "        M[task] = np.array(task_matrices)\n",
    "    test = np.concatenate((M['rfMRI_REST1_LR'], M['tfMRI_EMOTION_LR'],\n",
    "                           M['tfMRI_GAMBLING_LR'], M['tfMRI_LANGUAGE_LR'],\n",
    "                           M['tfMRI_MOTOR_LR'], M['tfMRI_RELATIONAL_LR'],\n",
    "                           M['tfMRI_SOCIAL_LR'], M['tfMRI_WM_LR']))\n",
    "    retest = np.concatenate((M['rfMRI_REST1_RL'], M['tfMRI_EMOTION_RL'],\n",
    "                             M['tfMRI_GAMBLING_RL'], M['tfMRI_LANGUAGE_RL'],\n",
    "                             M['tfMRI_MOTOR_RL'], M['tfMRI_RELATIONAL_RL'],\n",
    "                             M['tfMRI_SOCIAL_RL'], M['tfMRI_WM_RL']))\n",
    "    del M\n",
    "    all_FC = np.concatenate((test, retest))\n",
    "    del test, retest\n",
    "    return all_FC, nSubj\n",
    "\n",
    "\n",
    "def get_schaefer(parc, ref='none'):\n",
    "    if ref.lower() == 'none':\n",
    "        with open(f'../data/schaefer/schaefer{parc}.pickle', 'rb') as f:\n",
    "            all_FC = pickle.load(f)\n",
    "    else:\n",
    "        with open(f'../data/tangent_fcs/schaefer/schaefer{parc}_{ref}.pickle', 'rb') as f:\n",
    "            all_FC = pickle.load(f)\n",
    "    nSubj = int(all_FC.shape[0]/16)\n",
    "    return all_FC, nSubj\n",
    "\n",
    "\n",
    "def q1invm(q1, eig_thresh=0):\n",
    "    q1 += np.eye(q1.shape[0])\n",
    "    U, S, V = scipy.linalg.svd(q1)\n",
    "    S = np.diag(S ** (-1 / 2))\n",
    "    Q1_inv_sqrt = U @ S @ V\n",
    "    Q1_inv_sqrt = (Q1_inv_sqrt + np.transpose(Q1_inv_sqrt)) / 2\n",
    "    return Q1_inv_sqrt\n",
    "\n",
    "\n",
    "def qlog(q):\n",
    "    U, S, V = scipy.linalg.svd(q)\n",
    "    s = np.diag(S)\n",
    "    S = np.diag(np.log(s))\n",
    "    Q = U @ S @ V\n",
    "    return Q\n",
    "\n",
    "\n",
    "def tangential(all_FC, ref):\n",
    "    # Regularization for riemann\n",
    "    if ref in ['riemann', 'kullback_sym', 'logeuclid']:\n",
    "        print(\"Adding regularization!\")\n",
    "        eye_mat = np.eye(all_FC.shape[1])\n",
    "        scaling_mat = np.repeat(eye_mat[None, ...], all_FC.shape[0], axis=0)\n",
    "        all_FC += scaling_mat\n",
    "    Cg = mean_covariance(all_FC, metric=ref)\n",
    "    Q1_inv_sqrt = q1invm(Cg)\n",
    "    Q = Q1_inv_sqrt @ all_FC @ Q1_inv_sqrt\n",
    "    tangent_FC = np.empty(Q.shape)\n",
    "    for idx, fc in enumerate(Q):\n",
    "        if idx % 100 == 0:\n",
    "            print(f'{idx}/{Q.shape[0]}')\n",
    "        tangent_FC[idx] = linalg.logm(fc)\n",
    "    return tangent_FC\n",
    "\n",
    "\n",
    "def pca_recon(FC, pctComp=None):\n",
    "    '''\n",
    "    Reconstructs FC based on number of principle components\n",
    "    '''\n",
    "    if pctComp is None:\n",
    "        return FC\n",
    "    nRegions = FC.shape[1]\n",
    "    FC = np.reshape(FC, (FC.shape[0], -1))\n",
    "    nComp = int(FC.shape[0] * pctComp)\n",
    "    mu = np.mean(FC, axis=0)\n",
    "    pca_rest = sklearn.decomposition.PCA()\n",
    "    pca_rest.fit(FC)\n",
    "    cumsum = np.cumsum(pca_rest.explained_variance_ratio_)\n",
    "    SCORES = pca_rest.transform(FC)[:, :nComp]\n",
    "    COEFFS = pca_rest.components_[:nComp, :]\n",
    "    FC_recon = np.dot(SCORES, COEFFS)\n",
    "    del SCORES, COEFFS\n",
    "    FC_recon += mu\n",
    "    FC_recon = np.reshape(FC_recon, (FC.shape[0], nRegions, nRegions))\n",
    "    return FC_recon\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing all correlation matrices... All FCs successfully loaded!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Navigate tree and get raw correlation FC matrices\n",
    "print(\"Importing all correlation matrices...\", end=\" \")\n",
    "all_FC, nSubj = get_schaefer(100)\n",
    "print(\"All FCs successfully loaded!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate tree and get raw correlation FC matrices\n",
    "print(\"Importing all correlation matrices...\", end=\" \")\n",
    "all_FC, nSubj = get_glasser()\n",
    "print(\"All FCs successfully loaded!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for ref in ['euclid', 'riemann', 'kullback_sym', 'harmonic', 'logeuclid']:\n",
    "    print(f'{parc}:{ref}')\n",
    "    # Navigate tree and get raw correlation FC matrices\n",
    "    all_FC, nSubj = get_glasser()\n",
    "    print(\"All FCs successfully loaded!\\n\")\n",
    "    tangent_FCs = tangential(all_FC, ref)\n",
    "    with open(f'../data/tangent_fcs/glasser_{ref}.pickle', 'wb') as f:\n",
    "        pickle.dump(tangent_FCs, f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tangent_FCs[0],origin='lower')\n",
    "plt.ylabel('Brain Regions')\n",
    "plt.xlabel('Brain Regions')\n",
    "plt.colorbar()\n",
    "if ref == 'euclid':\n",
    "    plt.clim(-1,1)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([],[])\n",
    "plt.title(f'Tangent Projection: Euclidean Mean', fontdict = {'fontsize' : 20})\n",
    "plt.ylabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "plt.xlabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "plt.clim(-0.25, 0.25)\n",
    "plt.savefig(f'../results/tangent_fc_euclid.eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tangent_FCs[0],origin='lower')\n",
    "plt.ylabel('Brain Regions')\n",
    "plt.xlabel('Brain Regions')\n",
    "plt.colorbar()\n",
    "if ref == 'euclid':\n",
    "    plt.clim(-1,1)\n",
    "plt.xticks([], [])\n",
    "plt.yticks([],[])\n",
    "plt.title(f'Tangent Projection: LogEuclid Mean', fontdict = {'fontsize' : 20})\n",
    "plt.ylabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "plt.xlabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "plt.clim(-0.05, 0.05)\n",
    "plt.savefig(f'../results/tangent_fc_logeuclid.eps', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_FC, nSubj = get_glasser()\n",
    "with open(f'../data/glasser.pickle', 'wb') as f:\n",
    "    pickle.dump(all_FC, f, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot reference matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "for ref in ['kullback_sym']:\n",
    "    print(\"Importing all correlation matrices...\", end=\" \")\n",
    "    all_FC, nSubj = get_schaefer(100)\n",
    "    print(\"All FCs successfully loaded!\\n\")\n",
    "    print(ref)\n",
    "    if ref in ['riemann', 'kullback_sym', 'logeuclid']:\n",
    "        print(\"Adding regularization!\")\n",
    "        eye_mat = np.eye(all_FC.shape[1])\n",
    "        scaling_mat = np.repeat(eye_mat[None, ...], all_FC.shape[0], axis=0)\n",
    "        all_FC += scaling_mat\n",
    "    kullback_Cg = mean_covariance(all_FC, metric=ref)\n",
    "    plt.style.use('default')\n",
    "    sampleFC = kullback_Cg\n",
    "    plt.imshow(sampleFC,origin='lower')\n",
    "    plt.ylabel('Brain Regions')\n",
    "    plt.xlabel('Brain Regions')\n",
    "    plt.colorbar()\n",
    "    plt.clim(np.percentile(Cg, 5), np.percentile(Cg, 95))\n",
    "#     if ref == 'euclid':\n",
    "#         plt.clim(-1,1)\n",
    "        \n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([],[])\n",
    "    plt.title(f'{ref}', fontdict = {'fontsize' : 20})\n",
    "    plt.ylabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "    plt.xlabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "    plt.savefig(f'../results/tangent_references/reference_{ref}.eps', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_mat = euclid_Cg / kullback_Cg\n",
    "plt.style.use('default')\n",
    "sampleFC = diff_mat\n",
    "plt.imshow(sampleFC,origin='lower')\n",
    "plt.ylabel('Brain Regions')\n",
    "plt.xlabel('Brain Regions')\n",
    "plt.colorbar()\n",
    "plt.clim(np.percentile(Cg, 5), np.percentile(Cg, 95))\n",
    "#     if ref == 'euclid':\n",
    "#         plt.clim(-1,1)\n",
    "\n",
    "plt.xticks([], [])\n",
    "plt.yticks([],[])\n",
    "plt.title(f'Diff between Euclid and Kullback', fontdict = {'fontsize' : 20})\n",
    "plt.ylabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "plt.xlabel('Brain Regions',fontdict = {'fontsize' : 18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = 'task'\n",
    "if classifier == 'task':\n",
    "    labels = np.tile(np.repeat(np.arange(0, 8), nSubj), 2)\n",
    "    indices = np.random.permutation(nSubj)\n",
    "    train_idx = indices[:int(0.80 * nSubj)]\n",
    "    test_idx = indices[int(0.8 * nSubj):]\n",
    "    train_idx_all, test_idx_all = np.empty(0, dtype=int), np.empty(0, dtype=int)\n",
    "    for fc in np.arange(0, 16):\n",
    "        train_idx_all = np.concatenate((train_idx_all, (fc * nSubj) + train_idx)).astype(int)\n",
    "        test_idx_all = np.concatenate((test_idx_all, (fc * nSubj) + test_idx)).astype(int)\n",
    "    train_idx = train_idx_all\n",
    "    test_idx = test_idx_all\n",
    "elif classifier == 'subject':\n",
    "    labels = np.tile(np.tile(np.arange(0,nSubj),8),2)\n",
    "    indices = np.random.permutation(all_FC.shape[0])\n",
    "    train_idx = indices[:int(0.80 * all_FC.shape[0])]\n",
    "    test_idx = indices[int(0.80 * all_FC.shape[0]):]\n",
    "else:\n",
    "    pass\n",
    "\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing none reference with correlation distance...\n",
      "0.7786764705882353\n",
      "Testing none reference with cosine distance...\n",
      "0.7808823529411765\n",
      "Testing none reference with euclidean distance...\n",
      "0.6264705882352941\n",
      "Testing pca reference with correlation distance...\n",
      "0.8911764705882353\n",
      "Testing pca reference with cosine distance...\n",
      "0.888235294117647\n",
      "Testing pca reference with euclidean distance...\n",
      "0.8691176470588236\n",
      "Testing euclid reference with correlation distance...\n",
      "0.43161764705882355\n",
      "Testing euclid reference with cosine distance...\n",
      "0.4389705882352941\n",
      "Testing euclid reference with euclidean distance...\n",
      "0.25\n",
      "Testing harmonic reference with correlation distance...\n",
      "0.20441176470588235\n",
      "Testing harmonic reference with cosine distance...\n",
      "0.21029411764705883\n",
      "Testing harmonic reference with euclidean distance...\n",
      "0.25\n",
      "Testing logeuclid reference with correlation distance...\n",
      "0.8860294117647058\n",
      "Testing logeuclid reference with cosine distance...\n",
      "0.8897058823529411\n",
      "Testing logeuclid reference with euclidean distance...\n",
      "0.5367647058823529\n",
      "Testing kullback_sym reference with correlation distance...\n",
      "0.888235294117647\n",
      "Testing kullback_sym reference with cosine distance...\n",
      "0.8867647058823529\n",
      "Testing kullback_sym reference with euclidean distance...\n",
      "0.5360294117647059\n",
      "Testing riemann reference with correlation distance...\n",
      "0.8727941176470588\n",
      "Testing riemann reference with cosine distance...\n",
      "0.8676470588235294\n",
      "Testing riemann reference with euclidean distance...\n",
      "0.5352941176470588\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = {}\n",
    "for ref in ['none', 'pca', 'euclid', 'harmonic', 'logeuclid', 'kullback_sym', 'riemann']:\n",
    "    if ref == 'pca':\n",
    "        all_FC, nSubj = get_schaefer(100)\n",
    "        all_FC = pca_recon(all_FC, 0.012)\n",
    "    else:\n",
    "        all_FC, nSubj = get_schaefer(100, ref)\n",
    "    train_FCs = np.zeros((len(train_idx),6441), dtype=np.float32)\n",
    "    for idx, mat in enumerate(all_FC[train_idx]):\n",
    "        train_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "    test_FCs = np.zeros((len(test_idx),6441), dtype=np.float32)\n",
    "    for idx, mat in enumerate(all_FC[test_idx]):\n",
    "        test_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "    for distance_method in ['correlation', 'cosine', 'euclidean']:\n",
    "        print(f'Testing {ref} reference with {distance_method} distance...')\n",
    "        neigh = KNeighborsClassifier(n_neighbors=10, metric=distance_method)\n",
    "        neigh.fit(train_FCs, train_labels)\n",
    "        predicted = neigh.predict(test_FCs)\n",
    "        acc = accuracy_score(test_labels, predicted)\n",
    "        print(acc)\n",
    "        accuracies[ref+\"_\"+distance_method] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "a_file = open(f\"../results/tasks/distances_tangent.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Approach"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
