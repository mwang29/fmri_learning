{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "from scipy.spatial import distance\n",
    "import sys\n",
    "import os\n",
    "from scipy import linalg\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "\n",
    "def get_data(parc, twin='DZ'):\n",
    "    '''\n",
    "    Navigates through file tree and extracts test/retest FCs \n",
    "    '''\n",
    "    master_dir = '../data/twins'\n",
    "    tasks = ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']\n",
    "    FC, test, retest = {}, {}, {}\n",
    "    for task in tasks:\n",
    "        task_dir = master_dir + f'/{task.upper()}/origmat_{twin}_schaefer{parc}_tests.mat'\n",
    "        f = h5py.File(task_dir, 'r')\n",
    "        for k, v in f.items():\n",
    "            test[task] = np.array(v)\n",
    "        task_dir = master_dir + f'/{task.upper()}/origmat_{twin}_schaefer{parc}_retests.mat'\n",
    "        f = h5py.File(task_dir, 'r')\n",
    "        for k, v in f.items():\n",
    "            retest[task] = np.array(v)\n",
    "        FC[task] = np.concatenate((test[task], retest[task])) \n",
    "    return FC\n",
    "\n",
    "def utri2mat(utri):\n",
    "    n = int(-1 + np.sqrt(1 + 8 * len(utri))) // 2\n",
    "    iu1 = np.tril_indices(n+1,-1)\n",
    "    ret = np.empty((n+1, n+1))\n",
    "    ret[iu1] = utri\n",
    "    ret.T[iu1] = utri\n",
    "    np.fill_diagonal(ret, 1)\n",
    "    return ret\n",
    "\n",
    "def q1invm(q1, eig_thresh=0):\n",
    "    q1 += np.eye(q1.shape[0])\n",
    "    U, S, V = scipy.linalg.svd(q1)\n",
    "    S = np.diag(S ** (-1 / 2))\n",
    "    Q1_inv_sqrt = U @ S @ V\n",
    "    Q1_inv_sqrt = (Q1_inv_sqrt + np.transpose(Q1_inv_sqrt)) / 2\n",
    "    return Q1_inv_sqrt\n",
    "\n",
    "\n",
    "def tangential(all_FC, ref):\n",
    "    # Regularization for riemann\n",
    "    if ref in ['riemann', 'kullback_sym', 'logeuclid']:\n",
    "        print(\"Adding regularization!\")\n",
    "        eye_mat = np.eye(all_FC.shape[1])\n",
    "        scaling_mat = np.repeat(eye_mat[None, ...], all_FC.shape[0], axis=0)\n",
    "        all_FC += scaling_mat\n",
    "    Cg = mean_covariance(all_FC, metric=ref)\n",
    "    Q1_inv_sqrt = q1invm(Cg)\n",
    "    Q = Q1_inv_sqrt @ all_FC @ Q1_inv_sqrt\n",
    "    tangent_FC = np.empty(Q.shape)\n",
    "    for idx, fc in enumerate(Q):\n",
    "        if idx % 100 == 0:\n",
    "            print(f'{idx}/{Q.shape[0]}')\n",
    "        blockPrint()\n",
    "        tangent_FC[idx] = linalg.logm(fc)\n",
    "        enablePrint()\n",
    "    return tangent_FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "twin = 'MZ'\n",
    "FCs = get_data(100, twin=twin)\n",
    "nFCs = FCs['rest'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCs['rest']\n",
    "parc = 100\n",
    "FC = np.zeros((FCs['rest'].shape[0], parc+14, parc+14))\n",
    "for idx, utri in enumerate(FCs['rest']):\n",
    "    FC[idx] = utri2mat(utri)\n",
    "\n",
    "print(FC.shape)\n",
    "Cg = mean_covariance(FC, metric='euclid')\n",
    "tan_fcs = tangential(FC, 'euclid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train and test labels\n",
    "labels = np.tile(np.repeat(np.arange(0,FCs['rest'].shape[0]/4),2),2)\n",
    "labels = labels.astype(int)\n",
    "train_idx = np.arange(0,FCs['rest'].shape[0],2)\n",
    "train_idx = train_idx.astype(int)\n",
    "test_idx = np.arange(1, int(FCs['rest'].shape[0]), 2)\n",
    "test_idx = test_idx.astype(int)\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Approach - Manual Tangent Space, all Parcellations, all Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using logeuclid transformation\n",
      "\n",
      "Analyzing rest with Schaefer100...\n",
      "Accuracies: 0.50000 and 0.52155\n",
      "Analyzing emotion with Schaefer100...\n",
      "Accuracies: 0.28879 and 0.26724\n",
      "Analyzing gambling with Schaefer100...\n",
      "Accuracies: 0.40086 and 0.43966\n",
      "Analyzing language with Schaefer100...\n",
      "Accuracies: 0.62069 and 0.63362\n",
      "Analyzing motor with Schaefer100...\n",
      "Accuracies: 0.43103 and 0.46983\n",
      "Analyzing relational with Schaefer100...\n",
      "Accuracies: 0.40948 and 0.40517\n",
      "Analyzing social with Schaefer100...\n",
      "Accuracies: 0.53017 and 0.56466\n",
      "Analyzing wm with Schaefer100...\n",
      "Accuracies: 0.56897 and 0.57759\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-d23bf2259390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Using {ref} transformation\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mFCs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtwin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'rest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'emotion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gambling'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'language'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'motor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relational'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'social'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'original'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-9057fa35267f>\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(parc, twin)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mtask_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'/{task.upper()}/origmat_{twin}_schaefer{parc}_retests.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for ref in ['logeuclid', 'harmonic', 'kullback_sym', 'logeuclid', 'riemann']:\n",
    "    print(f\"Using {ref} transformation\\n\")\n",
    "    for parc in np.arange(100, 600, 100):\n",
    "        FCs = get_data(parc, twin=twin)\n",
    "        for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "            if ref != 'original':\n",
    "                with open(f'../data/tangent_fcs/twins/{task}/{twin}_{parc}_{ref}.pickle', 'rb') as f:\n",
    "                    task_FCs = pickle.load(f)\n",
    "                vec_FCs = np.zeros((nFCs, lengths[parc]), dtype=np.float32)\n",
    "                for idx, mat in enumerate(task_FCs):\n",
    "                    vec_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "            else:\n",
    "                vec_FCs = FCs[task]\n",
    "            print(f'Analyzing {task} with Schaefer{parc}...')\n",
    "            # Split into train and test sets\n",
    "            train_FCs = vec_FCs[train_idx]\n",
    "            test_FCs = vec_FCs[test_idx]\n",
    "            # KNN Classifier\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, metric='correlation')\n",
    "            neigh.fit(train_FCs, train_labels)\n",
    "            predicted = neigh.predict(test_FCs)\n",
    "            acc1 = accuracy_score(test_labels, predicted)\n",
    "            neigh.fit(test_FCs, test_labels)\n",
    "            predicted = neigh.predict(train_FCs)\n",
    "            acc2 = accuracy_score(test_labels, predicted)\n",
    "            average_acc = (acc1 + acc2) / 2\n",
    "            print(f'Accuracies: {acc1:.5f} and {acc2:.5f}')\n",
    "            accuracies[f\"{parc}:{task}:{ref}\"] = average_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save common tangent projected FCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/twins/{twin}_twin_parcellations_new.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent Space FCs - load premade tangent FCs, all parcellations, all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 region parcellation...\n",
      "Analyzing rest...\n",
      "0.05660 accuracy\n",
      "Analyzing emotion...\n",
      "0.01887 accuracy\n",
      "Analyzing gambling...\n",
      "0.03774 accuracy\n",
      "Analyzing language...\n",
      "0.04717 accuracy\n",
      "Analyzing motor...\n",
      "0.03774 accuracy\n",
      "Analyzing relational...\n",
      "0.00000 accuracy\n",
      "Analyzing social...\n",
      "0.02830 accuracy\n",
      "Analyzing wm...\n",
      "0.04717 accuracy\n",
      "Using 200 region parcellation...\n",
      "Analyzing rest...\n",
      "0.01887 accuracy\n",
      "Analyzing emotion...\n",
      "0.00943 accuracy\n",
      "Analyzing gambling...\n",
      "0.01887 accuracy\n",
      "Analyzing language...\n",
      "0.00943 accuracy\n",
      "Analyzing motor...\n",
      "0.00943 accuracy\n",
      "Analyzing relational...\n",
      "0.02830 accuracy\n",
      "Analyzing social...\n",
      "0.06604 accuracy\n",
      "Analyzing wm...\n",
      "0.01887 accuracy\n",
      "Using 300 region parcellation...\n",
      "Analyzing rest...\n",
      "0.00943 accuracy\n",
      "Analyzing emotion...\n",
      "0.00943 accuracy\n",
      "Analyzing gambling...\n",
      "0.00943 accuracy\n",
      "Analyzing language...\n",
      "0.04717 accuracy\n",
      "Analyzing motor...\n",
      "0.04717 accuracy\n",
      "Analyzing relational...\n",
      "0.00943 accuracy\n",
      "Analyzing social...\n",
      "0.00943 accuracy\n",
      "Analyzing wm...\n",
      "0.02830 accuracy\n",
      "Using 400 region parcellation...\n",
      "Analyzing rest...\n",
      "0.04717 accuracy\n",
      "Analyzing emotion...\n",
      "0.02830 accuracy\n",
      "Analyzing gambling...\n",
      "0.00000 accuracy\n",
      "Analyzing language...\n",
      "0.03774 accuracy\n",
      "Analyzing motor...\n",
      "0.02830 accuracy\n",
      "Analyzing relational...\n",
      "0.02830 accuracy\n",
      "Analyzing social...\n",
      "0.01887 accuracy\n",
      "Analyzing wm...\n",
      "0.02830 accuracy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "twin = 'MZ'\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for parc in np.arange(100,500,100):\n",
    "    print(f'Using {parc} region parcellation...')\n",
    "    for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "        print(f'Analyzing {task}...')\n",
    "        for ref in ['logeuclid']:\n",
    "            # Start with a fresh batch of FCs\n",
    "            with open(f'../data/tangent_fcs/twins/{task}/{twin}_{parc}_{ref}.pickle', 'rb') as f:\n",
    "                FC = pickle.load(f)\n",
    "            # Convert back into flattened utriu vectors\n",
    "            vec_FCs = np.zeros((nFCs, lengths[parc]), dtype=np.float32)\n",
    "            for idx, mat in enumerate(FC):\n",
    "                vec_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "            # Split into train and test sets\n",
    "            train_FCs = vec_FCs[train_idx]\n",
    "            test_FCs = vec_FCs[test_idx]\n",
    "            # KNN Classifier\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, metric='correlation')\n",
    "            neigh.fit(train_FCs, train_labels)\n",
    "            predicted = neigh.predict(test_FCs)\n",
    "            acc = accuracy_score(test_labels, predicted)\n",
    "            print(f'{acc:.5f} accuracy')\n",
    "            accuracies[f\"{parc}:{task}:{ref}\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/twins/{twin}_twin_logeuclid.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
