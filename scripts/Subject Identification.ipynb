{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'over': 'warn', 'under': 'ignore', 'invalid': 'ignore'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "import sklearn.datasets\n",
    "import sklearn.decomposition\n",
    "from scipy.spatial import distance\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utri2mat(utri):\n",
    "    n = int(-1 + np.sqrt(1 + 8 * len(utri))) // 2\n",
    "    iu1 = np.triu_indices(n+1,1)\n",
    "    ret = np.empty((n+1, n+1))\n",
    "    ret[iu1] = utri\n",
    "    ret.T[iu1] = utri\n",
    "    np.fill_diagonal(ret, 1)\n",
    "    return ret\n",
    "\n",
    "def get_data(parc, twin='DZ'):\n",
    "    '''\n",
    "    Navigates through file tree and extracts test/retest FCs \n",
    "    '''\n",
    "    # Yeo ordering\n",
    "    master_dir = '../data/twins'\n",
    "    tasks = ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']\n",
    "    FC, test, retest = {}, {}, {}\n",
    "    for task in tasks:\n",
    "        task_dir = master_dir + f'/{task.upper()}/origmat_{twin}_schaefer{parc}_tests.mat'\n",
    "        f = h5py.File(task_dir, 'r')\n",
    "        for k, v in f.items():\n",
    "            test[task] = np.array(v)\n",
    "        task_dir = master_dir + f'/{task.upper()}/origmat_{twin}_schaefer{parc}_retests.mat'\n",
    "        f = h5py.File(task_dir, 'r')\n",
    "        for k, v in f.items():\n",
    "            retest[task] = np.array(v)\n",
    "        FC[task] = np.concatenate((test[task], retest[task])) \n",
    "    return FC\n",
    "\n",
    "\n",
    "def q1invm(q1, eig_thresh=0):\n",
    "    U, S, V = scipy.linalg.svd(q1)\n",
    "    s = np.diag(S)\n",
    "    s[s < eig_thresh] = eig_thresh\n",
    "    S = np.diag(s ** (-1 / 2))\n",
    "    Q1_inv_sqrt = U * S * np.transpose(V)\n",
    "    Q1_inv_sqrt = (Q1_inv_sqrt + np.transpose(Q1_inv_sqrt)) / 2\n",
    "    return Q1_inv_sqrt\n",
    "\n",
    "\n",
    "def qlog(q):\n",
    "    U, S, V = scipy.linalg.svd(q)\n",
    "    s = np.diag(S)\n",
    "    S = np.diag(np.log(s))\n",
    "    Q = U * S * np.transpose(V)\n",
    "    return Q\n",
    "\n",
    "\n",
    "def tangential(all_FC, ref):\n",
    "    # Regularization for riemann\n",
    "    if ref in ['riemann', 'kullback_sym', 'logeuclid']: \n",
    "        print(\"Adding regularization!\")\n",
    "        eye_mat = np.eye(all_FC.shape[1])\n",
    "        scaling_mat = np.repeat(eye_mat[None, ...], all_FC.shape[0], axis=0)\n",
    "        all_FC += scaling_mat\n",
    "    u, s, vh = np.linalg.svd(all_FC[0], full_matrices=True)\n",
    "    Cg = mean_covariance(all_FC, metric=ref)\n",
    "    Q1_inv_sqrt = q1invm(Cg)\n",
    "    Q = Q1_inv_sqrt @ all_FC @ Q1_inv_sqrt\n",
    "    tangent_FC = np.array([qlog(a) for a in Q])\n",
    "    return tangent_FC\n",
    "\n",
    "\n",
    "def pca_recon(FC, pctComp=None):\n",
    "    '''\n",
    "    Reconstructs FC based on number of principle components\n",
    "    '''\n",
    "    if pctComp is None:\n",
    "        return FC\n",
    "    nRegions = FC.shape[1]\n",
    "    FC = np.reshape(FC, (FC.shape[0], -1))\n",
    "    nComp = int(FC.shape[0] * pctComp)\n",
    "    mu = np.mean(FC, axis=0)\n",
    "    pca_rest = sklearn.decomposition.PCA()\n",
    "    pca_rest.fit(FC)\n",
    "    SCORES = pca_rest.transform(FC)[:, :nComp]\n",
    "    COEFFS = pca_rest.components_[:nComp, :]\n",
    "    FC_recon = np.dot(SCORES, COEFFS)\n",
    "    del SCORES, COEFFS\n",
    "    FC_recon += mu\n",
    "    FC_recon = np.reshape(FC_recon, (FC.shape[0], nRegions, nRegions))\n",
    "    return FC_recon\n",
    "\n",
    "def utri2mat(utri):\n",
    "    n = int(-1 + np.sqrt(1 + 8 * len(utri))) // 2\n",
    "    iu1 = np.tril_indices(n+1,-1)\n",
    "    ret = np.empty((n+1, n+1))\n",
    "    ret[iu1] = utri\n",
    "    ret.T[iu1] = utri\n",
    "    np.fill_diagonal(ret, 1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twin Subject ID Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCs = get_data(100, twin=twin)\n",
    "labels = np.tile(np.repeat(np.arange(0,FCs['rest'].shape[0]/4),2),2)\n",
    "labels = labels.astype(int)\n",
    "train_idx = np.arange(0,FCs['rest'].shape[0],2)\n",
    "train_idx = train_idx.astype(int)\n",
    "test_idx = np.arange(1, int(FCs['rest'].shape[0]), 2)\n",
    "test_idx = test_idx.astype(int)\n",
    "train_labels = labels[train_idx]\n",
    "test_labels = labels[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Approach - Manual Tangent Space, all Parcellations, all Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing rest...\n",
      "Accuracies: 0.32075 and 0.36792\n",
      "Analyzing emotion...\n",
      "Accuracies: 0.09434 and 0.09434\n",
      "Analyzing gambling...\n",
      "Accuracies: 0.15094 and 0.18868\n",
      "Analyzing language...\n",
      "Accuracies: 0.29245 and 0.33019\n",
      "Analyzing motor...\n",
      "Accuracies: 0.07547 and 0.09434\n",
      "Analyzing relational...\n",
      "Accuracies: 0.08491 and 0.07547\n",
      "Analyzing social...\n",
      "Accuracies: 0.20755 and 0.14151\n",
      "Analyzing wm...\n",
      "Accuracies: 0.25472 and 0.21698\n",
      "Analyzing rest...\n",
      "Accuracies: 0.40566 and 0.39623\n",
      "Analyzing emotion...\n",
      "Accuracies: 0.10377 and 0.09434\n",
      "Analyzing gambling...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6d4686f47897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'correlation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_FCs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_FCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0macc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_FCs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m                 **kwds))\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ball_tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1592\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1593\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1594\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2778\u001b[0m             cdist_fn = getattr(_distance_wrap,\n\u001b[1;32m   2779\u001b[0m                                \"cdist_%s_%s_wrap\" % (metric_name, typ))\n\u001b[0;32m-> 2780\u001b[0;31m             \u001b[0mcdist_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2781\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_correlation_cdist_wrap\u001b[0;34m(XA, XB, dm, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mXA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mXB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXB\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0m_distance_wrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist_cosine_double_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for parc in np.arange(100, 500, 100):\n",
    "    common_FCs = get_data(parc, twin=twin)\n",
    "    for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "        print(f'Analyzing {task}...')\n",
    "        task_FCs = common_FCs[task]\n",
    "        # Do optional transformations\n",
    "        for ref in ['original']:\n",
    "            # Start with a fresh batch of FCs\n",
    "            FC = np.zeros((task_FCs.shape[0], parc+14, parc+14))\n",
    "            for idx, utri in enumerate(task_FCs):\n",
    "                FC[idx] = utri2mat(utri)\n",
    "            # Do optional transformations\n",
    "            if ref != 'original' and ref != 'pca':\n",
    "                FC = tangential(FC, ref)\n",
    "            elif ref == 'pca':\n",
    "                print('Reconstructing with PCA')\n",
    "                FC = pca_recon(FC, 0.3)\n",
    "            else:\n",
    "                pass\n",
    "            # Convert back into flattened utriu vectors\n",
    "            vec_FCs = np.zeros(\n",
    "                (nFCs, lengths[parc]), dtype=np.float32)\n",
    "            for idx, mat in enumerate(FC):\n",
    "                vec_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "            # Split into train and test sets\n",
    "            train_FCs = vec_FCs[train_idx]\n",
    "            test_FCs = vec_FCs[test_idx]\n",
    "            # KNN Classifier\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, metric='correlation')\n",
    "            neigh.fit(train_FCs, train_labels)\n",
    "            predicted = neigh.predict(test_FCs)\n",
    "            acc1 = accuracy_score(test_labels, predicted)\n",
    "            neigh.fit(test_FCs, test_labels)\n",
    "            predicted = neigh.predict(train_FCs)\n",
    "            acc2 = accuracy_score(test_labels, predicted)\n",
    "            print(f'Accuracies: {acc1:.5f} and {acc2:.5f}')\n",
    "            accuracies[f\"{parc}:{task}:{ref}\"] = (acc1 + acc2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save common tangent projected FCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing rest...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing emotion...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing gambling...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing language...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing motor...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing relational...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing social...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing wm...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing rest...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing emotion...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing gambling...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing language...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing motor...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing relational...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing social...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing wm...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing rest...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing emotion...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing gambling...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing language...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing motor...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing relational...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing social...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing wm...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing rest...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing emotion...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing gambling...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing language...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing motor...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing relational...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing social...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n",
      "Analyzing wm...\n",
      "saved euclid\n",
      "saved harmonic\n",
      "Adding regularization!\n",
      "saved kullback_sym\n",
      "Adding regularization!\n",
      "saved logeuclid\n",
      "Adding regularization!\n",
      "saved riemann\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for parc in np.arange(100, 500, 100):\n",
    "    common_FCs = get_data(test_twin_ind, retest_twin_ind, parc, twin=twin)\n",
    "    for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "        print(f'Analyzing {task}...')\n",
    "        task_FCs = common_FCs[task]\n",
    "        # Do optional transformations\n",
    "        for ref in ['euclid', 'harmonic', 'kullback_sym', 'logeuclid', 'riemann']:\n",
    "            # Start with a fresh batch of FCs\n",
    "            FC = np.zeros((task_FCs.shape[0], parc+14, parc+14))\n",
    "            for idx, utri in enumerate(task_FCs):\n",
    "                FC[idx] = utri2mat(utri)\n",
    "            # Do optional transformations\n",
    "            FC = tangential(FC, ref)\n",
    "            with open(f'../data/tangent_fcs/twins/common/{task}/{twin}_{parc}_{ref}.pickle', 'wb') as f:\n",
    "                pickle.dump(FC, f)\n",
    "            print(f\"saved {ref}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'100:rest:original': 0.3443396226415094,\n",
       " '100:emotion:original': 0.09433962264150944,\n",
       " '100:gambling:original': 0.169811320754717,\n",
       " '100:language:original': 0.3113207547169811,\n",
       " '100:motor:original': 0.0849056603773585,\n",
       " '100:relational:original': 0.08018867924528301,\n",
       " '100:social:original': 0.17452830188679247,\n",
       " '100:wm:original': 0.2358490566037736,\n",
       " '200:rest:original': 0.4009433962264151,\n",
       " '200:emotion:original': 0.09905660377358491,\n",
       " '200:gambling:original': 0.2169811320754717,\n",
       " '200:language:original': 0.4056603773584906,\n",
       " '200:motor:original': 0.1320754716981132,\n",
       " '200:relational:original': 0.14622641509433962,\n",
       " '200:social:original': 0.25471698113207547,\n",
       " '200:wm:original': 0.3160377358490566,\n",
       " '300:rest:original': 0.4339622641509434,\n",
       " '300:emotion:original': 0.10377358490566038,\n",
       " '300:gambling:original': 0.25943396226415094,\n",
       " '300:language:original': 0.42924528301886794,\n",
       " '300:motor:original': 0.12735849056603774,\n",
       " '300:relational:original': 0.17452830188679247,\n",
       " '300:social:original': 0.3018867924528302,\n",
       " '300:wm:original': 0.33018867924528306,\n",
       " '400:rest:original': 0.4481132075471698,\n",
       " '400:emotion:original': 0.12264150943396226,\n",
       " '400:gambling:original': 0.24056603773584906,\n",
       " '400:language:original': 0.4811320754716981,\n",
       " '400:motor:original': 0.12735849056603774,\n",
       " '400:relational:original': 0.1792452830188679,\n",
       " '400:social:original': 0.32075471698113206,\n",
       " '400:wm:original': 0.34905660377358494}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/twins/{twin}_twin_parcellations_new.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tangent Space FCs - load premade tangent FCs, all parcellations, all tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 100 region parcellation...\n",
      "Analyzing rest...\n",
      "0.50000 accuracy\n",
      "Analyzing emotion...\n",
      "0.28879 accuracy\n",
      "Analyzing gambling...\n",
      "0.40086 accuracy\n",
      "Analyzing language...\n",
      "0.62069 accuracy\n",
      "Analyzing motor...\n",
      "0.43103 accuracy\n",
      "Analyzing relational...\n",
      "0.40948 accuracy\n",
      "Analyzing social...\n",
      "0.53017 accuracy\n",
      "Analyzing wm...\n",
      "0.56897 accuracy\n",
      "Using 200 region parcellation...\n",
      "Analyzing rest...\n",
      "0.61638 accuracy\n",
      "Analyzing emotion...\n",
      "0.47845 accuracy\n",
      "Analyzing gambling...\n",
      "0.61207 accuracy\n",
      "Analyzing language...\n",
      "0.79741 accuracy\n",
      "Analyzing motor...\n",
      "0.68103 accuracy\n",
      "Analyzing relational...\n",
      "0.59483 accuracy\n",
      "Analyzing social...\n",
      "0.71121 accuracy\n",
      "Analyzing wm...\n",
      "0.71121 accuracy\n",
      "Using 300 region parcellation...\n",
      "Analyzing rest...\n",
      "0.66810 accuracy\n",
      "Analyzing emotion...\n",
      "0.62069 accuracy\n",
      "Analyzing gambling...\n",
      "0.68534 accuracy\n",
      "Analyzing language...\n",
      "0.82759 accuracy\n",
      "Analyzing motor...\n",
      "0.78448 accuracy\n",
      "Analyzing relational...\n",
      "0.69397 accuracy\n",
      "Analyzing social...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bf0e9c122634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mneigh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'correlation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_FCs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_FCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{acc:.5f} accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m                 **kwds))\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ball_tree'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kd_tree'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[0;32m-> 1592\u001b[0;31m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[1;32m   1593\u001b[0m         if ((X is Y or Y is None)\n\u001b[1;32m   1594\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2778\u001b[0m             cdist_fn = getattr(_distance_wrap,\n\u001b[1;32m   2779\u001b[0m                                \"cdist_%s_%s_wrap\" % (metric_name, typ))\n\u001b[0;32m-> 2780\u001b[0;31m             \u001b[0mcdist_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2781\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fmri/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36m_correlation_cdist_wrap\u001b[0;34m(XA, XB, dm, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mXA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXA\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mXB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXB\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0m_distance_wrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist_cosine_double_wrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracies = {}\n",
    "twin = 'MZ'\n",
    "lengths = {100:6441, 200:22791, 300:49141, 400:85491, 500:131841}\n",
    "for parc in np.arange(100,500,100):\n",
    "    print(f'Using {parc} region parcellation...')\n",
    "    for task in ['rest', 'emotion', 'gambling', 'language', 'motor', 'relational', 'social', 'wm']:\n",
    "        print(f'Analyzing {task}...')\n",
    "        for ref in ['logeuclid']:\n",
    "            # Start with a fresh batch of FCs\n",
    "            with open(f'../data/tangent_fcs/twins/{task}/{twin}_{parc}_{ref}.pickle', 'rb') as f:\n",
    "                FC = pickle.load(f)\n",
    "            # Convert back into flattened utriu vectors\n",
    "            vec_FCs = np.zeros((nFCs, lengths[parc]), dtype=np.float32)\n",
    "            for idx, mat in enumerate(FC):\n",
    "                vec_FCs[idx] = mat[np.triu_indices(mat.shape[0], k=1)]\n",
    "            # Split into train and test sets\n",
    "            train_FCs = vec_FCs[train_idx]\n",
    "            test_FCs = vec_FCs[test_idx]\n",
    "            # KNN Classifier\n",
    "            neigh = KNeighborsClassifier(n_neighbors=1, metric='correlation')\n",
    "            neigh.fit(train_FCs, train_labels)\n",
    "            predicted = neigh.predict(test_FCs)\n",
    "            acc = accuracy_score(test_labels, predicted)\n",
    "            print(f'{acc:.5f} accuracy')\n",
    "            accuracies[f\"{parc}:{task}:{ref}\"] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FCs[220:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(f\"../results/twins/{twin}_twin_logeuclid.csv\", \"w\")\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in accuracies.items():\n",
    "    writer.writerow([key, value])\n",
    "    \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
